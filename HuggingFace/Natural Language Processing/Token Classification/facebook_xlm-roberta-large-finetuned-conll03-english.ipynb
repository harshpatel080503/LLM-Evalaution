{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f72e756",
   "metadata": {},
   "source": [
    "## FacebookAI :- xlm-roberta-large-finetuned-conll03-english"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310b8c29",
   "metadata": {},
   "source": [
    "Model Description\n",
    "\n",
    "The XLM-RoBERTa model was proposed in Unsupervised Cross-lingual Representation Learning at Scale by Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm√°n, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov. It is based on Facebook's RoBERTa model released in 2019. It is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl data. This model is XLM-RoBERTa-large fine-tuned with the conll2003 dataset in English.\n",
    "\n",
    "Model type: Multi-lingual language model\n",
    "\n",
    "Language(s) (NLP) or Countries (images): XLM-RoBERTa is a multilingual model trained on 100 different languages; see GitHub Repo for full list; model is fine-tuned on a dataset in English\n",
    "\n",
    "Uses\n",
    "\n",
    "Direct Use\n",
    "The model is a language model. The model can be used for token classification, a natural language understanding task in which a label is assigned to some tokens in a text.\n",
    "\n",
    "Downstream Use\n",
    "Potential downstream use cases include Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging. To learn more about token classification and other potential downstream use cases, see the Hugging Face token classification docs.\n",
    "\n",
    "Out-of-Scope Use\n",
    "The model should not be used to intentionally create hostile or alienating environments for people.\n",
    "\n",
    "Bias, Risks, and Limitations\n",
    "CONTENT WARNING: Readers should be made aware that language generated by this model may be disturbing or offensive to some and may propagate historical and current stereotypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a09473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Data Science Study\\Project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9e66d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b3c7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(\n",
    "    provider = \"hf-inference\",\n",
    "    api_key = os.environ[\"HF_TOKEN\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a8e0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.token_classification(\n",
    "    \"Sundar Pichai met Satya Nadella in New York to discuss a partnership between Google and Microsoft before traveling to London.\",\n",
    "    model=\"FacebookAI/xlm-roberta-large-finetuned-conll03-english\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec8c93c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TokenClassificationOutputElement(end=13, score=0.999992, start=0, word='Sundar Pichai', entity=None, entity_group='PER'),\n",
       " TokenClassificationOutputElement(end=31, score=0.99999493, start=18, word='Satya Nadella', entity=None, entity_group='PER'),\n",
       " TokenClassificationOutputElement(end=43, score=0.9999977, start=35, word='New York', entity=None, entity_group='LOC'),\n",
       " TokenClassificationOutputElement(end=83, score=0.9999782, start=77, word='Google', entity=None, entity_group='ORG'),\n",
       " TokenClassificationOutputElement(end=97, score=0.9999746, start=88, word='Microsoft', entity=None, entity_group='ORG'),\n",
       " TokenClassificationOutputElement(end=124, score=0.99999833, start=118, word='London', entity=None, entity_group='LOC')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
