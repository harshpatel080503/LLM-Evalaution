{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "105696ef",
   "metadata": {},
   "source": [
    "## IBM Granite :- Granite Guardian HAP 38M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd065dbd",
   "metadata": {},
   "source": [
    "Model Summary:-\n",
    "\n",
    "This model is IBM's lightweight, 4-layer toxicity binary classifier for English. Its latency characteristics make it a suitable guardrail for any large language model. It can also be used for bulk processing of data where high throughput is needed. It has been trained on several benchmark datasets in English, specifically for detecting hateful, abusive, profane and other toxic content in plain text.\n",
    "\n",
    "Developers: IBM Research\n",
    "Release Date: September 6th, 2024\n",
    "License: Apache 2.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08764344",
   "metadata": {},
   "source": [
    "======================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2214908e",
   "metadata": {},
   "source": [
    "Usage\n",
    "\n",
    "This model offers very low inference latency and is capable of running on CPUs apart from GPUs and AIUs. It features 38 million parameters, reducing the number of hidden layers from 12 to 4, decreasing the hidden size from 768 to 576, and the intermediate size from 3072 to 768, compared to the original RoBERTa model architecture. The latency on CPU vs accuracy numbers for this model in comparision to others is shown in the chart below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b843f6e8",
   "metadata": {},
   "source": [
    "========================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783aa0eb",
   "metadata": {},
   "source": [
    "Ethical Considerations and Limitations\n",
    "\n",
    "The use of model-based guardrails for Large Language Models (LLMs) involves risks and ethical considerations people must be aware of. This model operates on chunks of texts and provides a score indicating the presence of hate speech, abuse, or profanity. However, the efficacy of the model can be limited by several factors: the potential inability to capture nuanced meanings or the risk of false positives or negatives on text that is dissimilar to the training data. Previous research has demonstrated the risk of various biases in toxicity or hate speech detection. That is also relevant to this work. We urge the community to use this model with ethical intentions and in a responsible way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b72087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Data Science Study\\Project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c715f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a7e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(\n",
    "    provider = \"hf-inference\",\n",
    "    api_key = os.environ[\"HF_TOKEN\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56fee5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.text_classification(\n",
    "    \"\"\"I’m not threatening anyone, but people like you really don’t belong in serious conversations.\n",
    "You slow everyone down, and things would honestly work better if you just stayed quiet.\n",
    "\"\"\",\n",
    "    model=\"ibm-granite/granite-guardian-hap-38m\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "004f25e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextClassificationOutputElement(label='NOT HARMFUL', score=0.996728777885437),\n",
       " TextClassificationOutputElement(label='HARMFUL', score=0.0032712456304579973)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for r in result:\n",
    "    if r.label == \"LABEL_0\":\n",
    "        r.label = \"NOT HARMFUL\"\n",
    "    else:\n",
    "        r.label = \"HARMFUL\"\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
