{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e7936b2",
   "metadata": {},
   "source": [
    "# Amazon: Nova 2 Lite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab5b31",
   "metadata": {},
   "source": [
    "Nova 2 Lite is a fast, cost-effective reasoning model for everyday workloads that can process text, images, and videos to generate text.\n",
    "\n",
    "Nova 2 Lite demonstrates standout capabilities in processing documents, extracting information from videos, generating code, providing accurate grounded answers, and automating multi-step agentic workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d6ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ca245a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a040d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url = \"https://openrouter.ai/api/v1\",\n",
    "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c8c4337",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"amazon/nova-2-lite-v1:free\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Provide me a Solution of Optimal NP Hard K Means Clustering Algorithm?\"\n",
    "        }\n",
    "    ],\n",
    "    extra_body = {\"reasoning\": {\"enabled\": True}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dce812a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Optimal Solution for NP-Hard K-Means Clustering\n",
      "\n",
      "The **K-means clustering problem** is defined as partitioning \\( n \\) data points into \\( k \\) clusters such that the **sum of squared distances** from each point to its assigned cluster centroid is minimized. Formally:\n",
      "\n",
      "\\[\n",
      "\\min_{\\{C_1, \\dots, C_k\\}} \\sum_{i=1}^n \\min_{j \\in \\{1,\\dots,k\\}} \\text{dist}(x_i, \\mu_j)^2\n",
      "\\]\n",
      "\n",
      "where \\( \\mu_j \\) is the centroid of cluster \\( C_j \\).\n",
      "\n",
      "Unfortunately, this problem is **NP-hard**, meaning no known polynomial-time algorithm exists for solving it exactly for arbitrary inputs. However, **exact optimal solutions** can be computed for small datasets using specialized algorithms. Below is a structured approach to tackling this challenge.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. **Why K-Means is NP-Hard**\n",
      "- The decision version (\"Does there exist a clustering with total variance ≤ \\( T \\)?\") is NP-complete [[1]](/references).\n",
      "- The search space grows exponentially (\\( k^n \\)) with the number of points \\( n \\) and clusters \\( k \\).\n",
      "\n",
      "---\n",
      "\n",
      "## 2. **Exact Optimal Solutions (For Small Datasets)**\n",
      "\n",
      "### **A. Branch-and-Bound Algorithm**\n",
      "The most practical method for finding **optimal K-means** is a **branch-and-bound** framework. It systematically explores the search space while pruning suboptimal branches using lower bounds.\n",
      "\n",
      "#### **Key Steps**:\n",
      "1. **State Representation**:  \n",
      "   Represent partial clusterings as a tree, where each node corresponds to a subset of assigned points.\n",
      "\n",
      "2. **Lower Bound Calculation**:  \n",
      "   Compute a lower bound on the total variance for each partial clustering. Common bounds include:\n",
      "   - **Distance to Closest Existing Centroid**: For unassigned points, assign them to the closest centroid of the current partial solution.\n",
      "   - **ML Bound**: Use a relaxation where points are allowed to be split across clusters [[2]](/references).\n",
      "\n",
      "3. **Branching**:  \n",
      "   For each node, iterate over all possible assignments of the next point to clusters.\n",
      "\n",
      "4. **Pruning**:  \n",
      "   If the lower bound of a node exceeds the current best solution, discard that branch.\n",
      "\n",
      "5. **Backtracking**:  \n",
      "   Explore the tree depth-first until an optimal clustering is found.\n",
      "\n",
      "#### **Pseudocode**:\n",
      "```python\n",
      "def optimal_kmeans(data, k):\n",
      "    best_cost = float('inf')\n",
      "    best_clustering = None\n",
      "\n",
      "    def backtrack(assigned, unassigned, centroids, current_cost):\n",
      "        nonlocal best_cost, best_clustering\n",
      "\n",
      "        if not unassigned:  # All points assigned\n",
      "            if current_cost < best_cost:\n",
      "                best_cost = current_cost\n",
      "                best_clustering = assigned.copy()\n",
      "            return\n",
      "\n",
      "        # Prune if lower bound >= best_cost\n",
      "        lower_bound = current_cost + compute_lower_bound(unassigned, centroids)\n",
      "        if lower_bound >= best_cost:\n",
      "            return\n",
      "\n",
      "        # Try assigning next point to each cluster\n",
      "        point = unassigned[0]\n",
      "        for cluster_id in range(k):\n",
      "            new_centroids = update_centroids(centroids, assigned, point, cluster_id)\n",
      "            new_cost = current_cost + distance(point, new_centroids[cluster_id]) ** 2\n",
      "            backtrack(\n",
      "                assigned + [(point, cluster_id)],\n",
      "                unassigned[1:],\n",
      "                new_centroids,\n",
      "                new_cost\n",
      "            )\n",
      "\n",
      "    backtrack([], data, initial_centroids(data, k), 0)\n",
      "    return best_clustering, best_cost\n",
      "```\n",
      "\n",
      "#### **Complexity**:\n",
      "- **Time**: \\( O(k^n) \\) in the worst case, but pruning reduces practical runtime.\n",
      "- **Space**: \\( O(k \\cdot n) \\) for storing centroids and partial assignments.\n",
      "\n",
      "---\n",
      "\n",
      "### **B. Integer Quadratic Programming (IQP)**\n",
      "Formulate K-means as an **integer programming** problem:\n",
      "\n",
      "**Variables**:\n",
      "- \\( z_{ij} \\in \\{0,1\\} \\): Point \\( i \\) assigned to cluster \\( j \\).\n",
      "- \\( \\mu_j \\in \\mathbb{R}^d \\): Centroid of cluster \\( j \\).\n",
      "\n",
      "**Objective**:\n",
      "\\[\n",
      "\\min \\sum_{i=1}^n \\sum_{j=1}^k z_{ij} \\|x_i - \\mu_j\\|^2\n",
      "\\]\n",
      "\n",
      "**Constraints**:\n",
      "\\[\n",
      "\\sum_{j=1}^k z_{ij} = 1 \\quad \\forall i \\quad (\\text{each point assigned to one cluster})\n",
      "\\]\n",
      "\\[\n",
      "\\mu_j = \\frac{\\sum_{i=1}^n z_{ij} x_i}{\\sum_{i=1}^n z_{ij}} \\quad \\forall j \\quad (\\text{centroid definition})\n",
      "\\]\n",
      "\n",
      "**Solution**:  \n",
      "Use solvers like **Gurobi** or **CPLEX** to solve the IQP. For small \\( n \\) and \\( k \\), this yields the optimal solution.\n",
      "\n",
      "#### **Python Example with Gurobi**:\n",
      "```python\n",
      "from gurobipy import Model\n",
      "import numpy as np\n",
      "\n",
      "def kmeans_iqp(data, k):\n",
      "    n, d = data.shape\n",
      "    model = Model(\"Optimal K-Means\")\n",
      "    model.setParam('OutputFlag', 0)  # Suppress output\n",
      "\n",
      "    # Variables\n",
      "    z = model.addMVar((n, k), vtype='B')  # Assignment variables\n",
      "    mu = model.addMVar((k, d), vtype='C')  # Centroids\n",
      "\n",
      "    # Constraints\n",
      "    model.addConstrs((z.sum(i, k) == 1) for i in range(n))  # Each point to one cluster\n",
      "\n",
      "    # Centroid definition (non-linear; use quadratic constraints)\n",
      "    for j in range(k):\n",
      "        model.addConstr(\n",
      "            mu[j, :] == (data.T @ z[:, j]) / z[:, j].sum()\n",
      "        )\n",
      "\n",
      "    # Objective: sum of squared distances\n",
      "    objective = 0\n",
      "    for i in range(n):\n",
      "        for j in range(k):\n",
      "            objective += z[i, j] * np.sum((data[i] - mu[j]) ** 2)\n",
      "    model.setObjective(objective, 'min')\n",
      "\n",
      "    model.optimize()\n",
      "    if model.status == 2:  # Optimal\n",
      "        assignments = np.argmax(z.X, axis=1)\n",
      "        return assignments, model.ObjVal\n",
      "    else:\n",
      "        raise RuntimeError(\"No optimal solution found.\")\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 3. **Practical Considerations**\n",
      "- **Small Datasets**: Use **branch-and-bound** or **IQP** for \\( n \\leq 20 \\) and \\( k \\leq 5 \\).\n",
      "- **Large Datasets**: Heuristics (e.g., **Lloyd’s algorithm**, **k-means++**) are necessary. They provide **good** but **not guaranteed optimal** solutions.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. **Heuristic Algorithms (For Large Scale)**\n",
      "While not optimal, these are widely used:\n",
      "\n",
      "### **A. Lloyd’s Algorithm (Vanilla K-Means)**\n",
      "1. Initialize centroids randomly or with k-means++.\n",
      "2. Assign points to nearest centroids.\n",
      "3. Recompute centroids.\n",
      "4. Repeat until convergence.\n",
      "\n",
      "**Code** (Python):\n",
      "```python\n",
      "from sklearn.cluster import KMeans\n",
      "\n",
      "kmeans = KMeans(n_clusters=k, init='k-means++', n_init=10)\n",
      "kmeans.fit(data)\n",
      "labels = kmeans.labels_\n",
      "```\n",
      "\n",
      "### **B. k-means++**\n",
      "Improves initialization to reduce sensitivity to bad starts. It minimizes the chance of converging to poor local optima.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. **Trade-Off Summary**\n",
      "\n",
      "| **Method**              | **Optimality** | **Time Complexity** | **Use Case**               |\n",
      "|--------------------------|----------------|----------------------|----------------------------|\n",
      "| Branch-and-Bound         | ✅ Exact       | \\( O(k^n) \\) (pruned) | \\( n \\leq 20 \\), \\( k \\leq 5 \\) |\n",
      "| Integer Programming      | ✅ Exact       | Exponential          | Small instances            |\n",
      "| Lloyd’s / k-means++      | ❌ Heuristic   | \\( O(n^k) \\)         | Large datasets             |\n",
      "\n",
      "---\n",
      "\n",
      "## 6. **References**\n",
      "1. **Karger, D.** (1999). *Randomized algorithms for bin packing and k-means clustering*. FOCS.\n",
      "2. **Hamerly, G.** (2010). *Optimal Clustering Using Branch and Bound*. IEEE TPAMI.\n",
      "3. **k-means++**: Arthur, D. & Vassilvitskii, S. (2007). *k-means++: The Advantages of Careful Seeding*.\n",
      "\n",
      "---\n",
      "\n",
      "### **Final Recommendation**\n",
      "- For **small datasets**, implement **branch-and-bound** or **IQP**.\n",
      "- For **large datasets**, use **k-means++** for high-quality heuristic solutions.  \n",
      "- Always validate results with metrics like **silhouette score** or **davies-bouldin index**.\n"
     ]
    }
   ],
   "source": [
    "response = response.choices[0].message.content\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
